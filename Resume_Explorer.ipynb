{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import minecart\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad21669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "    \n",
    "# creating a pdf file object \n",
    "pdfFileObj = open('resumes/Senior Risk Modelling Analyst.pdf', 'rb') \n",
    "    \n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "    \n",
    "# printing number of pages in pdf file \n",
    "print(pdfReader.numPages) \n",
    "    \n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(0) \n",
    "    \n",
    "# extracting text from page \n",
    "text_data=pageObj.extractText()\n",
    "    \n",
    "# closing the pdf file object \n",
    "#pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dac4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d4e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfReader.getPage(1).extractText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7671f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mobile_number(text):\n",
    "    '''\n",
    "    Helper function to extract mobile number from text\n",
    "    :param text: plain text extracted from resume file\n",
    "    :return: string of extracted mobile numbers\n",
    "    '''\n",
    "    # Found this complicated regex on : https://zapier.com/blog/extract-links-email-phone-regex/\n",
    "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    "        if len(number) > 10:\n",
    "            return '+' + number\n",
    "        else:\n",
    "            return number\n",
    "        \n",
    "def extract_name(nlp_text, matcher):\n",
    "    '''\n",
    "    Helper function to extract name from spacy nlp text\n",
    "    :param nlp_text: object of `spacy.tokens.doc.Doc`\n",
    "    :param matcher: object of `spacy.matcher.Matcher`\n",
    "    :return: string of full name\n",
    "    '''\n",
    "    pattern = [cs.NAME_PATTERN]\n",
    "    \n",
    "    matcher.add('NAME', None, *pattern)\n",
    "    \n",
    "    matches = matcher(nlp_text)\n",
    "    \n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text\n",
    "    \n",
    "def extract_email(text):\n",
    "    '''\n",
    "    Helper function to extract email id from text\n",
    "    :param text: plain text extracted from resume file\n",
    "    '''\n",
    "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", text)\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08193368",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_email(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef39226",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESUME_SECTIONS = [\n",
    "                    'accomplishments',\n",
    "                    'experience',\n",
    "                    'educational qualifications',\n",
    "                    'interests',\n",
    "                    'projects',\n",
    "                    'professional experience',\n",
    "                    'publications',\n",
    "                    'skills',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcffea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity_sections(text):\n",
    "    '''\n",
    "    Helper function to extract all the raw text from sections of resume\n",
    "    :param text: Raw text of resume\n",
    "    :return: dictionary of entities\n",
    "    '''\n",
    "    text_split = [i.strip() for i in text.split('\\n')]\n",
    "    # sections_in_resume = [i for i in text_split if i.lower() in sections]\n",
    "    entities = {}\n",
    "    key = False\n",
    "    for phrase in text_split:\n",
    "        if len(phrase) == 1:\n",
    "            p_key = phrase\n",
    "        else:\n",
    "            p_key = set(phrase.lower().split()) & set(RESUME_SECTIONS)\n",
    "        try:\n",
    "            p_key = list(p_key)[0]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        if p_key in RESUME_SECTIONS:\n",
    "            entities[p_key] = []\n",
    "            key = p_key\n",
    "        elif key and phrase.strip():\n",
    "            entities[key].append(phrase)\n",
    "    \n",
    "    # entity_key = False\n",
    "    # for entity in entities.keys():\n",
    "    #     sub_entities = {}\n",
    "    #     for entry in entities[entity]:\n",
    "    #         if u'\\u2022' not in entry:\n",
    "    #             sub_entities[entry] = []\n",
    "    #             entity_key = entry\n",
    "    #         elif entity_key:\n",
    "    #             sub_entities[entity_key].append(entry)\n",
    "    #     entities[entity] = sub_entities\n",
    "\n",
    "    # pprint.pprint(entities)\n",
    "\n",
    "    # make entities that are not found None\n",
    "    # for entity in cs.RESUME_SECTIONS:\n",
    "    #     if entity not in entities.keys():\n",
    "    #         entities[entity] = None \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ee9541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508e2adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_split = [i.strip() for i in text_data.lower().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e0a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(clean_text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88c2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def get_pdf_content_lines(pdf_file_path):\n",
    "    with open(pdf_file_path) as f:\n",
    "        pdf_reader = PdfFileReader(f)\n",
    "        for page in pdf_reader.pages: \n",
    "            for line in page.extractText().splitlines():\n",
    "                yield line\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35dc9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list=['january',\n",
    "'february',\n",
    "'march',\n",
    "'april',\n",
    "'may',\n",
    "'june',\n",
    "'july',\n",
    "'august',\n",
    "'september',\n",
    "'october',\n",
    "'november',\n",
    "'december',\n",
    "'jan',\n",
    "'feb',\n",
    "'mar',\n",
    "'apr',\n",
    "'may',\n",
    "'jun',\n",
    "'jul',\n",
    "'aug',\n",
    "'sep',\n",
    "'oct',\n",
    "'nov',\n",
    "'dec',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba615bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience=[]\n",
    "for i,line in enumerate(clean_text.split(\",\")):\n",
    "    print(set([line for month in month_list if month in line]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1636c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = re.findall('(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[\\s-]\\d{2,4}', clean_text)\n",
    "print(results)\n",
    "\n",
    "doc=nlp(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea40bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,line in enumerate(clean_text.split(\",\")):\n",
    "    results = re.findall('(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)[\\s-]\\d{2,4}', line.lower())\n",
    "    if results:\n",
    "        doc = nlp(line)\n",
    "        print(results,[ent for ent in doc.ents])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35309c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#spacy_text = nlp(text)\n",
    "#atcher = Matcher(nlp.vocab, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afdff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    \n",
    "matcher.add('NAME',[pattern])\n",
    "\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff4dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# matcher = Matcher(nlp.vocab,validate=True)\n",
    "# patterns = [\n",
    "#     [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "# ]\n",
    "# matcher.add(\"process_1\", patterns)\n",
    "\n",
    "# texts= [\"it is a beautiful apple\", \"it is a beautiful and big apple\"]\n",
    "doc = nlp(clean_text)\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    print(doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d601bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\",\".join([\"a\",\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f22be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    for token in sent.ents:\n",
    "        print(token)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1b176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7d45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_objects import Resume,Job\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11da372a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "resumes/CICC_Aaron Chao_Research Analyst.pdf Professional Experience\n",
      "4\n",
      "resumes/DBS Vickers_Eric Yee_Senior Research Analyst.pdf ERIC YEE\n",
      "1\n",
      "resumes/Dymon_Allen Liu_Research Analyst.pdf Allen Liu\n",
      "1\n",
      "resumes/Anbang AM_Claire Shen_Equity Analyst.pdf Claire Shen\n",
      "1\n",
      "resumes/Allard Partners_Ng Xin Yao_Investment Analyst.pdf NG Xin\n"
     ]
    }
   ],
   "source": [
    "for file in glob.glob(\"resumes/*.pdf\"):\n",
    "    resume=Resume(file)\n",
    "    print(file,resume.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db3236",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resume.all_education[0][\"institutes\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717daed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_education\n",
    "from constants import EDUCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in resume.all_experience:\n",
    "    education_tokens = [tokens for education in EDUCATION for tokens in val[1] if education in tokens.lower()]\n",
    "    if education_tokens:\n",
    "        education_details = {\"time_of_education\": val[0],\n",
    "                                 \"institutes\": education_tokens}\n",
    "        print(education_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66a5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data=Resume(\"resumes/Anbang AM_Claire Shen_Equity Analyst.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4aaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.skill_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93ebb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prof_experience = []\n",
    "for val in resume.all_experience:\n",
    "    experience_tokens = [tokens for education in EDUCATION for tokens in val[1] if\n",
    "                         education not in tokens.text.lower() if tokens.label_ == \"ORG\"]\n",
    "    print(experience_tokens)\n",
    "    if experience_tokens:\n",
    "        education_details = {\"time_of_education\": val[0],\n",
    "                             \"institutes\": experience_tokens}\n",
    "        prof_experience.append(education_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040aacc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(['apr 10', 'may 12','jul 2015', 'mar 2014','jun 09', 'mar 10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ba673",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,chunk in enumerate(all_data.spacy_text.noun_chunks):\n",
    "    print(chunk)\n",
    "    if len(chunk)>2 and \"experience\" in chunk.text.lower():\n",
    "        exp_index=i\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435105",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,chunk in enumerate(all_data.spacy_text.noun_chunks):\n",
    "    if i>=exp_index and len(chunk)>=2:\n",
    "        print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17685e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"resumes/Senior Risk Modelling Analyst\", \"r\")\n",
    "job_decription = f.read().replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7e49d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda7b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sentences=nlp(job_decription)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffbe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[sentence for sentence in job_sentences.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d87d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.encode(all_data.skill_dump)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e06d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume=Resume(\"resumes/Allard Partners_Ng Xin Yao_Investment Analyst.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c32fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume.doc_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7003aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm import get_cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8096c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_path=\"resumes/\"\n",
    "jd_path = \"resumes/Senior Risk Modelling Analyst\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b15940a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "resumes = []\n",
    "for file in glob.glob(resume_path + \"*.pdf\"):\n",
    "    resume_object = Resume(file)\n",
    "    resumes.append(resume_object)\n",
    "\n",
    "# get the job description\n",
    "job = Job(jd_path)\n",
    "\n",
    "resume_job_sim = get_cosine_similarity(resumes, job)\n",
    "\n",
    "df_resume = pd.DataFrame({\"resume_objects\": resumes, \"similarity\": resume_job_sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "173c5016",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume = pd.DataFrame({\"resume_objects\": resumes, \"similarity\": resume_job_sim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f648ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume[\"name\"]=df_resume.apply(lambda row: row.resume_objects.name,axis=1)\n",
    "df_resume[\"mobile\"]=df_resume.apply(lambda row: row.resume_objects.mobile_number,axis=1)\n",
    "df_resume[\"email\"]=df_resume.apply(lambda row: row.resume_objects.email,axis=1)\n",
    "df_resume[\"education\"]=df_resume.apply(lambda row: set([exp for val in row.resume_objects.all_education for vals in val.values() for exp in vals]),axis=1)\n",
    "df_resume[\"experience\"]=df_resume.apply(lambda row: set([exp for val in row.resume_objects.all_prof_orgs for vals in val.values() for exp in vals]),axis=1)\n",
    "df_resume[\"skills\"]=df_resume.apply(lambda row: [skill.text for skill in row.resume_objects.skill_dump],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9a9b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume=df_resume.resume_objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "daf7674d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "resume_objects    <data_objects.Resume object at 0x7fd9d7ca9240>\n",
       "similarity                                              0.920506\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4bce3582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume=df_resume.sort_values(\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edfa4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume[\"rank\"] = df_resume[\"similarity\"].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a85695e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume=df_resume.drop([\"resume_objects\"],axis=1)\n",
    "df_resume=df_resume.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ca2cbd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'time_of_education': ['jul 2015',\n",
       "   'mar 2014',\n",
       "   'jun 2015',\n",
       "   'oct 2011',\n",
       "   'feb 2014',\n",
       "   'mar 2010',\n",
       "   'sep 2011',\n",
       "   'dec 2009',\n",
       "   'may 2008'],\n",
       "  'institutes': [BOSTON UNIVERSITY, OLIN BUSINESS SCHOOL]}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resume[\"education\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fed73d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "pprint(df_resume.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "785ee8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3194c480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in df_resume[\"experience\"][0]:\n",
    "    val.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16159b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oct 2013', 'jun 2013', 'apr 2015', Shenyin & Wanguo SecuritiesShanghai                                                                                       2011, China/HK, Standard Chartered BankHong Kong, Jan Research Analyst, 'nov 2013'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([exp for val in row.resume_objects.all_prof_orgs for vals in val.values() for exp in vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1fced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
